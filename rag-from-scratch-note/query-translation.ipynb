{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation \n",
    "- Vấn đề ảnh hưởng tới hiệu quả của quá trình trích xuất thông tin đó là việc người dùng cung cấp thông tin mù mờ, không rõ ràng. Việc câu hỏi không rõ ràng dẫn tới trích xuất thông tin cũng không rõ ràng -> ảnh hưởng tới việc hiểu của LLM và kết quả của LLM \n",
    "\n",
    "- Một cách để giải quyết vấn đề này là thực hiện một vài phương pháp tiền xử lý đầu vào của người dùng (xử lý câu hỏi của người dùng) nhằm giúp câu hỏi trở nên rõ ràng, nhiều góc độ hơn. \n",
    "\n",
    "- Query Translation là một chuỗi các hành động xử lý trong quá trình embedding giữa query và docs để đảm bảo thông tin được trích xuất luôn được đảm bảo tính chính xác.   \n",
    "\n",
    "- Các cách để chuyển đổi câu query : \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"../doc/image/general-approaches-transform-question.png\" alt=\"basic-pipeline\" width=\"400\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_ENDPOINT = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Indexing \n",
    "import bs4 \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# loader thông qua nguồn là trang web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://en.wikipedia.org/wiki/Faker_(gamer)\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"mw-body-content\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma \n",
    "\n",
    "# khởi tạo vectorstore lưu trữ thông tin \n",
    "vectorstore = Chroma.from_documents(documents= splits, \n",
    "        embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",  google_api_key = GOOGLE_API_KEY))\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-written \n",
    "- Với các câu hỏi khó hiểu do cách diễn đạt của người dùng (không trừu tượng quá mà cũng không quá cụ thể), có hai cách thức chính để xử lý với dạng câu hỏi kiểu này đó là Multi-query và RAG-Fusion \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-query \n",
    "1. **Ý tưởng**: Ta có thể giải quyết vấn đề trên thông qua việc chuyển đổi, viết lại câu query của người dùng theo nhiều các khác nhau. Việc này đựa trên niềm tin rằng ngôn từ mà người dùng xử dụng sau khi embedding không thể trích xuất ra từ ngữ một cách chính xác. Việc viết lại sẽ cho câu query nhiều góc độ quan sát hơn, thông tin được đa dạng hơn\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"../doc/image/multi-query.png\" alt=\"basic-pipeline\" width=\"400\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate five \\ndifferent versions of the given user question to retrieve relevant documents from a vector \\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search. \\nProvide these alternative questions separated by newlines. Original question: {question}'))])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000205A8E8D2D0>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x00000205A8F9A110>, default_metadata=())\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cài đặt multi-query ## \n",
    "\n",
    "# viết lại tập câu hỏi thông qua mô hình ngôn ngữ lớn. \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "\n",
    "prompt_perspective = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspective\n",
    "    | ChatGoogleGenerativeAI(model = 'gemini-1.5-pro-latest', temperature = 0, api_key = GOOGLE_API_KEY)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "generate_queries\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "INPUT : \n",
    "You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: How many World Championship titles has Faker won in his League of Legends career?\n",
    "\n",
    "RENDER OUTPUT : \n",
    "Here are five alternative ways to phrase the question \"How many World Championship titles has Faker won in his League of Legends career?\" to enhance search results in a vector database:\n",
    "\n",
    "1. What is the total number of League of Legends World Championships won by Faker?\n",
    "2. How many times has Faker been crowned a League of Legends World Champion?\n",
    "3. What is Faker's World Championship win count in professional League of Legends?\n",
    "4. In the history of League of Legends, how many World Championship titles belong to Faker?\n",
    "5.  List the years Faker won the League of Legends World Championship. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(docs : list[list]): \n",
    "    # lấy ra thông tin duy nhất được trích xuất từ câu hỏi đầu vào \n",
    "    flattened_docs = [dumps(doc) for sublist in docs for doc in sublist]\n",
    "\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "question = \"How many World Championship titles has Faker won in his League of Legends career?\"\n",
    "\n",
    "# tạo ra retrieval chain, với đầu vào là câu một số câu query được tạo ra truóc đó -> lấy doc liên quan thông qua retriever -> tìm docs duy nhất trong số đó. \n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content='During the 2023 LCK Spring Split, Faker achieved another LCK record. On January 20, 2023, in a match against KT Rolster, Faker surpassed Kang \"Gorilla\" Beom-hyeon to claim the record for the most career assists in the history of the LCK at 4,137.[77] On July 2, in the 2023 LCK Summer Split, Faker was sidelined due to an arm injury. His absence from competitive play extended for a duration of four weeks. During this time, T1\\'s record fell from 6–2 to 7–9. Faker returned to the starting roster on August 2, helping the team defeat the Kwangdong Freecs.[78][79] Winning their last game of the season, T1 finished with a 9–9 record, securing the fifth seed in the LCK Summer playoffs.[80] T1 reached the LCK Summer finals, where they lost to Gen.G. Finishing with the most championship points in the LCK, the team qualified for the 2023 World Championship, marking Faker\\'s eighth Worlds appearance.[81][82] Faker won his fourth Worlds title on November 19, 2023, after T1 defeated Weibo Gaming in the finals. With the win, Faker became the first person to win four World Championship titles and, at age 27, the oldest player to win one.[83] At the 2023 LCK Awards ceremony in'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content='^ Alexander, Jem (October 27, 2019). \"The best League of Legends players: top pros from across the globe\". PCGamesN. Archived from the original on March 6, 2023. Retrieved March 5, 2023.\\n\\n^ Gubert, Jéssica (December 20, 2022). \"League of Legends stars with the most World Championships\". Dot Esports. Archived from the original on March 6, 2023. Retrieved March 5, 2023.\\n\\n^ Dyer, Mitch (November 2, 2015). \"Worlds: How SK Telecom T1 Won the 2015 League of Legends Championship\". IGN. Archived from the original on March 6, 2023. Retrieved March 5, 2023.\\n\\n^ East, Tom (October 12, 2016). \"Watch Faker\\'s strange LoL Worlds celebration\". Red Bull. Archived from the original on March 6, 2023. Retrieved March 5, 2023.\\n\\n^ Gu, Rachel (November 1, 2015). \"League of Legends team becomes first ever two time World Champions\". GameSpot. Archived from the original on March 6, 2023. Retrieved March 5, 2023.\\n\\n^ a b Bencomo, Brian (October 31, 2022). \"A legendary career: Faker\\'s results at Worlds and MSI\". Nerd Street. Archived from the original on March 6, 2023. Retrieved March 5, 2023.'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content='Faker celebrating after winning the 2023 World Championship'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content='Faker competing at the 2015 League of Legends World Championship\\nFaker celebrating after winning the 2015 World Championship'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content='defeating Griffin in the playoff finals, giving Faker his eighth LCK title.[48] At the 2019 World Championship, Faker became the first player to reach 100 international wins, after SKT defeated Splyce in the quarterfinals.[49] However, SKT were defeated in the semifinals by G2 Esports, marking the first time that Faker had been eliminated from Worlds in the knockout stage.[50]'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Faker_(gamer)'}, page_content=\"Faker's individual achievements include accolades such as a World Championship Most Valuable Player (MVP) award, an MSI MVP award, two LCK season MVP awards, an LCK Finals MVP award, an LCK Player of the Year award, an LCK Mid Laner of the Year award, and two LCK First All-Pro Team designations. He holds several LCK records, including being the first player to reach 1,000, 2,000, and 3,000 kills, the first to have earned 5,000 assists, the first to have played 900 games, and the first to have won 600 games in the LCK. Faker also holds the record for the most kills in World Championship matches and was the first player to surpass 100 World Championship wins. His accomplishments have earned him recognition as the Best Esports Athlete at The Game Awards in 2017 and 2023, PC Player of the Year at the Esports Awards in 2023, and he was named to the Forbes 30 Under 30 list in Asia Entertainment & Sports in 2019. Additionally, he was inducted into the ESL Hall of Fame in the same year. He was also chosen as the inaugural inductee for the LoL Esports Hall of Legends, being officially announced by Riot Games in May 2024.\")]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final pipeline with multi-query \n",
    "\n",
    "from operator import itemgetter \n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template) \n",
    "llm = ChatGoogleGenerativeAI(model = 'gemini-1.5-pro-latest', temperature = 0, api_key = GOOGLE_API_KEY)\n",
    "\n",
    "# xây dựng final chain thực hiện liên tục sinh multi-query -> lấy context phù hợp -> prompt -> llm -> ouput \n",
    "final_rag_chain = (\n",
    "    {'context': retrieval_chain, \n",
    "     'question' : itemgetter(\"question\")}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# trích xuất câu hỏi từ chain \n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo \n",
    "[Query Translation for RAG (Retrieval Augmented Generation)Applications](https://raghunaathan.medium.com/query-translation-for-rag-retrieval-augmented-generation-applications-46d74bff8f07)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
